# Kubernetes
![](https://1000logos.net/wp-content/uploads/2022/07/Kubernetes-Logo.png)
## Основные объекты Kubernetes
Эти объекты представляют приложения и инфраструктуру в кластере:

* Pod:

Минимальная единица развертывания в Kubernetes.
Может содержать один или несколько контейнеров, работающих совместно.
* Service:

Обеспечивает постоянный доступ к подам.
Поддерживает балансировку нагрузки и абстрагирует поды от изменений их IP.
* Deployment:

Управляет созданием и масштабированием подов.
Обеспечивает обновления без простоя (Rolling Updates).
* StatefulSet:

Управляет состоянием приложений с сохранением уникальных идентификаторов для каждого пода.
* DaemonSet:

Запускает поды на всех или некоторых узлах кластера.
* Job и CronJob:
    - Job: выполняет задачи до их завершения.
    - CronJob: выполняет задачи по расписанию.
# Kubernetes Architecture
![](https://shipit.dev/static/images/k8s-architecture.svg)
## Controll Plane
### API Server
API server - ключевой компонент Kubernetes, который отвечает за управление всеми запросами к API кластера. Он является центральной точкой взаимодействия всех компонентов Kubernetes и обеспечивает связь между пользователями, приложениями, контроллерами и узлами кластера. 

Он похож на начальный шлюз для кластера, который прослушивает обновления или запросы через CLI, например Kubectl. Kubectl взаимодействует с API-сервером, чтобы информировать о том, что необходимо сделать, например, создать модули или удалить модули и т. д. Он также работает как привратник. Обычно он проверяет полученные запросы, а затем пересылает их другим процессам. Ни один запрос не может быть передан кластеру напрямую, он должен быть передан через API-сервер.

### Kube-Scheduler
Kube-Scheduler - процесс плоскости управления, который назначает Pod узлам. Планировщик определяет, какие Node являются допустимыми размещениями для каждого Pod в очереди планирования в соответствии с ограничениями и доступными ресурсами. Затем планировщик ранжирует каждый допустимый Node и привязывает Pod к подходящему Node. В кластере можно использовать несколько различных планировщиков; kube-scheduler — это эталонная реализация.  

### Controller Manager
В состав controller manager входит несколько контроллеров, каждый из которых отвечает за определенный аспект управления кластером:
* Replication Controller: обеспечивает запуск необходимого количества реплик Pod для развертываний или наборов реплик.
* Endpoints Controller: : поддерживает объект конечных точек для каждой службы, отражая текущий набор модулей, поддерживающих эту службу.
* Namespace Controller: создает и управляет пространствами имен Kubernetes, предоставляя способ изоляции ресурсов.
* Service Account Controller: создает и управляет учетными записями служб, используемыми для аутентификации и авторизации Pod.
* Node Controller: отслеживает работоспособность и доступность узлов в кластере.
* Token Controller: отвечает за выдачу токенов аутентификации для учетных записей служб.
* Lease Controller: обеспечивает соблюдение механизмов аренды определенных ресурсов для предотвращения конфликтов и поддержания координации.

Основные обязанности:

Отвечает за запуск контроллеров, которые обрабатывают различные аспекты цикла управления кластером. Эти контроллеры включают контроллер репликации, который обеспечивает запуск нужного количества реплик данного приложения, и контроллер узла, который обеспечивает правильную маркировку узлов как «готовых» или «не готовых» на основе их текущего состояния.

### ETCD
Это хранилище ключей и значений кластера. Изменения состояния кластера сохраняются в etcd. Он действует как мозг кластера, поскольку сообщает планировщику и другим процессам о доступных ресурсах и об изменениях состояния кластера.

### Cluster DNS
Это внутренний DNS-сервис, который позволяет контейнерам и подам в кластере Kubernetes обращаться друг к другу по именам хостов, а не по IP-адресам. Он используется для разрешения доменных имен сервисов и подов внутри кластера, а также для предоставления внешних DNS-ресурсов.

Kubernetes обычно использует CoreDNS или kube-dns как основной DNS-сервер для разрешения имен в кластере.
По умолчанию, все сервисы в Kubernetes создают 

DNS-записи в формате \<service-name\>.\<namespace\>.svc.cluster.local. Например, сервис с именем my-service в пространстве имен default будет доступен 

### Cloud Controller Manager
Это компонент в Kubernetes, который отвечает за интеграцию Kubernetes с облачными провайдерами (такими как AWS, GCP, Azure и другие). Он управляет облачными ресурсами, такими как балансировщики нагрузки, диски, сети и узлы, и позволяет Kubernetes использовать эти ресурсы для управления кластером.

CCM запускается как отдельный процесс в Kubernetes, обычно в виде пода в пространстве имен kube-system.

Службы: Каждый облачный провайдер имеет свой собственный контроллер. Например:

* CloudNodeController — контроллер управления узлами.
* CloudServiceController — контроллер для работы с сервисами типа LoadBalancer.
* CloudVolumeController — контроллер для работы с томами.

Роль CCM:
* Когда кластер Kubernetes требует создания облачных ресурсов (например, создание балансировщика нагрузки для сервиса типа LoadBalancer), Cloud Controller Manager вызывает соответствующий облачный API для выполнения этой операции.
* Он также управляет жизненным циклом узлов: если новый узел добавляется в кластер, CCM будет взаимодействовать с облачным провайдером для его создания.

## Worker Node
### Kube-proxy
Kube-Proxy — это агент Kubernetes, установленный накаждый узелв кластере. Он отслеживает изменения, которые происходят с объектами Service и их конечными точками. Затем он транслирует эти изменения в фактические сетевые правила внутри узла.

Kube-Proxy обычно работает в вашем кластере в форме DaemonSet . Но его также можно установить напрямую как процесс Linux на узле. Это зависит от типа установки вашего кластера.

Если вы используете kubeadm , он установит Kube-Proxy как DaemonSet. Если вы вручную установите компоненты кластера с помощью официальных бинарных файлов Linux tarball, он будет запущен непосредственно как процесс на узле.

После установки Kube-proxy он проходит аутентификацию на сервере API. Когда добавляются или удаляются новые службы или конечные точки, сервер API сообщает об этих изменениях Kube-Proxy.

Затем Kube-Proxy применяет эти изменения как правила NAT внутри узла. Эти правила NAT — просто сопоставления IP-адреса сервиса с IP-адресом пода.

Когда трафик отправляется в службу, он перенаправляется на внутренний модуль на основе этих правил.

### Kubelet
Это основной «агент узла», который работает на каждом узле. Он может зарегистрировать узел в apiserver, используя одно из: имя хоста; флаг для переопределения имени хоста; или конкретную логику для облачного провайдера.

Kubelet работает в терминах PodSpec. PodSpec — это объект YAML или JSON, описывающий pod. Kubelet принимает набор PodSpec, которые предоставляются через различные механизмы (в основном через apiserver), и обеспечивает, чтобы контейнеры, описанные в этих PodSpec, были запущены и работоспособны. Kubelet не управляет контейнерами, которые не были созданы Kubernetes.
### Container Runtime 
Это программное обеспечение, которое отвечает за создание, управление и запуск контейнеров на узлах Kubernetes. Это компонент, через который Kubernetes взаимодействует с контейнерами. Он является обязательным для работы Kubernetes, так как без него невозможно запускать контейнеры, которые находятся в подах.

## Kubernetes Workload Objects
### Pods
Это фундаментальная единица развертывания в Kubernetes. Pod представляет собой группу из одного или нескольких контейнеров, которые тесно связаны и совместно используют хранилище (обычно том). Рабочие нагрузки обычно состоят из одного или нескольких Pods. 

Пример конфигурации YAML для Pod для запуска веб-приложения:
```yml 
apiVersion: v1
kind: Pod
metadata:
 name: web-app
spec:
 containers:
 - name: web-server
   image: nginx:latest  
   ports:
   - containerPort: 80
```
* `Init Containers`

Контейнеры Init всегда выполняются до завершения.
Каждый контейнер init должен успешно завершиться перед запуском следующего.
Если init-контейнер Pod выходит из строя, kubelet многократно перезапускает этот init-контейнер, пока он не завершится успешно. Однако, если Pod имеет значение restartPolicyNever, и init-контейнер выходит из строя во время запуска этого Pod, Kubernetes рассматривает весь Pod как неудавшийся.
* `Init Containers`

    - Основной контейнер (Main Container):

    Это основной контейнер, который выполняет основную задачу или сервис в Pod’е. Например, веб-приложение или API сервер.
    - Сайдкар контейнер (Sidecar Container):

    Это вспомогательные контейнеры, которые работают вместе с основным контейнером. Они могут выполнять дополнительные задачи, такие как логирование, мониторинг, синхронизация данных и т. д. Пример использования — контейнер с прокси-сервером, кешем или агентом мониторинга.
### Horizontal Pod Autoscaler
Этот объект отвечает за автоматическое масштабирование числа Pod'ов на основе различных метрик (например, загрузки процессора или использования памяти). Он помогает увеличивать или уменьшать количество реплик Pod'ов в зависимости от текущей нагрузки на систему.
### ReplicationController
Это объект в Kubernetes, который управляет количеством реплик (экземпляров) Pod'ов в кластере, обеспечивая их стабильное количество. Он был введён для обеспечения масштабируемости и отказоустойчивости приложений, управляемых Kubernetes.

Если вы создаёте ReplicationController с числом реплик, равным 3, то Kubernetes будет поддерживать три экземпляра этого Pod'а в любом момент времени. Если один из Pods будет уничтожен или выйдет из строя, ReplicationController создаст новый Pod, чтобы вернуть общее количество обратно до трёх.

Пример конфигурации ReplicationController (YAML):
```yml
apiVersion: v1
kind: ReplicationController
metadata:
  name: example-rc
spec:
  replicas: 3
  selector:
    app: example
  template:
    metadata:
      labels:
        app: example
    spec:
      containers:
      - name: example-container
        image: example-image:latest
```
- replicas: 3 — указывает, что должно быть три реплики Pod'ов.
- selector — определяет, какие Pod'ы должны управляться этим ReplicationController (в данном случае Pod'ы с меткой app: example).
- template — задаёт шаблон для создания Pod'ов, указывая контейнеры, которые должны быть запущены внутри этих Pod'ов.

### Deployment
Предназначен для управления развертыванием, обновлением и масштабированием приложения в виде Pod'ов. Deployment предоставляет удобные средства для автоматического обновления, отката и масштабирования приложения, упрощая управление жизненным циклом приложений в кластере Kubernetes.

Как работает Deployment:
ReplicaSet: Когда создается Deployment, он автоматически генерирует объект ReplicaSet, который следит за состоянием Pod'ов и поддерживает нужное количество реплик.

Rolling Update: Когда вы обновляете образ контейнера или конфигурацию, Deployment будет поэтапно заменять старые Pod'ы новыми. Это гарантирует, что приложение всегда будет доступно, а не будет полностью остановлено на время обновления.

Особенности Deployment:
* Поддержка стратегий обновления:
    - Rolling Update: Обновление Pod'ов происходит поэтапно, при этом старые Pod'ы удаляются по мере создания новых.
    - Recreate: Весь набор Pod'ов сначала удаляется, а затем создается заново (этот метод реже используется).
* Автоматическое восстановление: Если в кластере происходит сбой, Kubernetes автоматически создает недостающие Pod'ы, чтобы поддерживать нужное количество реплик.
* Откаты: Если новое обновление оказалось неудачным, можно легко вернуться к предыдущей версии.

### ReplicaSet
Цель ReplicaSet — поддерживать стабильный набор реплик Pod, работающих в любой момент времени. Обычно вы определяете Deployment и позволяете этому Deployment автоматически управлять ReplicaSets.

ReplicaSets подходят для более простых развертываний, где скользящие обновления не являются критически важными. Они обычно используются при развертывании приложений с сохранением состояния (в сочетании с Persistent Volumes для сохранения данных) или при запуске реплик баз данных для обеспечения высокой доступности.

ReplicaSet определяется полями, включая селектор, который указывает, как идентифицировать Pod, которые он может получить, количество реплик, указывающее, сколько Pod он должен поддерживать, и шаблон Pod, указывающий данные новых Pod, которые он должен создать, чтобы соответствовать критериям количества реплик. Затем ReplicaSet выполняет свое предназначение, создавая и удаляя Pod по мере необходимости для достижения желаемого числа. Когда ReplicaSet необходимо создать новые Pod, он использует свой шаблон Pod.
### StatefulSet
Это объект, предназначенный для управления состоянием приложений, которые требуют стабильных сетевых идентификаторов, постоянных хранилищ и упорядоченного развертывания и обновлений. Он используется для приложений, которым необходимо сохранять уникальные идентификаторы, имена хостов, а также привязанные тома, которые должны сохраняться даже после перезапуска или пересоздания Pod'ов.

StatefulSet является идеальным решением для таких приложений, как базы данных, кэш-системы и другие stateful приложения, где порядок и сохранность состояния критичны.

### Job
Задания представляют собой одноразовые задачи, которые выполняются до завершения, а затем останавливаются.
Job создает один или несколько Pod и будет продолжать повторять попытки выполнения Pod до тех пор, пока указанное количество из них не будет успешно завершено. По мере успешного завершения Pod задание отслеживает успешные завершения. Когда достигается указанное количество успешных завершений, задача (т. е. Job) завершается. Удаление Job очистит Pod, которые он создал. Приостановка Job удалит его активные Pod, пока Job не будет возобновлен снова.

Простой случай — создать один объект Job для надежного запуска одного Pod до завершения. Объект Job запустит новый Pod, если первый Pod выйдет из с

### CronJob

CronJob предназначен для выполнения регулярных заданий по расписанию, таких как резервное копирование, создание отчетов, и так далее. Один CronJob объект — это как одна строка файла crontab (cron table) в Unix-системе. Он периодически запускает задание по заданному расписанию, составленному в формате формате Cron.

У CronJob'a есть свои ограничения и особенности. Например, при определенных обстоятельствах один CronJob может создавать несколько параллельных заданий. См. раздел Ограничения ниже.

Когда управляющий слой (control plane) создает новые задания и (косвенно) поды для CronJob'а, поле .metadata.name в CronJob является частью основы для наименования этих подов. Имя CronJob должно быть действительным значением поддомена DNS, но это может привести к неожиданным результатам для имен хостов подов. Для наилучшей совместимости имя должно соответствовать более строгим правилам имен меток DNS. Даже если имя является поддоменом DNS, оно не должно превышать 52 символов. Это связано с тем, что контроллер CronJob автоматически добавляет 11 символов к указанному вами имени и существует ограничение на то, что длина имени задания (Job) не должна превышать 63 символа.

## DaemonSets

DaemonSets — это объекты API Kubernetes, которые позволяют запускать Pod в качестве демона на каждом из ваших узлов. Новые узлы, которые присоединяются к кластеру, автоматически запускают Pod, которые являются частью DaemonSet. DaemonSets часто используются для запуска долгоживущих фоновых служб, таких как системы мониторинга узлов и агенты сбора журналов. Для обеспечения полного покрытия важно, чтобы эти приложения запускали Pod на каждом узле в вашем кластере.

По умолчанию Kubernetes управляет вашими DaemonSets, так что каждый узел всегда запускает экземпляр Pod. Вы можете дополнительно настроить конфигурацию DaemonSet, чтобы только подмножество ваших Nodes планировало Pod.

Когда новые узлы присоединяются к вашему кластеру, они автоматически начинают запускать соответствующие Pod, которые определены DaemonSets. Аналогично, Kubernetes отменит планирование этих Pod и запустит сборку мусора, когда узлы будут депровизированы.

Поскольку DaemonSets разработаны для надежного запуска Pod на каждом узле, они поставляются с допусками по умолчанию , которые позволяют им планировать новые Pod в ситуациях, которые обычно были бы предотвращены. Например, DaemonSet Pods будут по-прежнему планироваться, даже если целевой узел сталкивается с ограничениями ресурсов или не принимает новые Pods.

## Kubernetes Networking Obects

### Ingress
Ingress — это объект, который позволяет получать доступ к службам Kubernetes из-за пределов кластера Kubernetes. Вы можете настроить доступ, создав набор правил, которые определяют, какие входящие соединения достигают тех или иных служб.

Ingress — это API-объект, который управляет внешним доступом к сервисам в кластере, обычно HTTP. Это означает, что вы можете использовать Ingress, чтобы сделать свой сервис доступным извне.
* Ingress не является типом службы, но действует как точка входа для кластера.
* Ingress предлагает упрощенные решения шлюзового типа.
* Ingress позволяет объединить правила маршрутизации в единый ресурс и предоставить доступ к нескольким сервисам под одним и тем же IP-адресом, используя одни и те же балансировщики нагрузки.
* Ingress также позволяет настраивать устойчивость (тайм-ауты, ограничение скорости), маршрутизацию на основе содержимого, аутентификацию и многое другое.

Ingress это ресурс в Kubernetes, который описывает правила маршрутизации для входящего трафика. Он определяет, как трафик должен быть направлен на сервисы внутри кластера.
### Ingress Class
IngressClass в Kubernetes — это объект, который позволяет указать, какой Ingress Controller должен управлять определённым Ingress ресурсом. В Kubernetes может быть несколько Ingress Controllers в одном кластере, и с помощью IngressClass можно явно указать, какой из них должен обрабатывать входящий трафик для конкретного ресурса Ingress.

### Ingress Controller
Ingress Controller в Kubernetes — это компонент, который реализует спецификации Ingress ресурсов и управляет маршрутизацией входящего трафика (например, HTTP и HTTPS) в кластер. Он фактически выполняет роль прокси, который направляет запросы на соответствующие Service в Kubernetes, в зависимости от правил, указанных в объекте Ingress.

### Service
Это метод предоставления доступа к сетевому приложению, работающему как одно или несколько Pod в вашем кластере.

Service является объектом, который обеспечивает доступ к набору Pod'ов, распределяя трафик между ними. Это основной объект для балансировки нагрузки. Он может быть настроен с использованием различных типов доступа:
* ClusterIP — доступен только внутри кластера.
* NodePort — доступен через статический порт на всех узлах.
* LoadBalancer — создает внешний балансировщик нагрузки.
* ExternalName — указывает внешний DNS-ресурс.
* Headless Services — позволяет вам использовать DNS-запросы для обнаружения индивидуальных IP-адресов любых Pod, выбранных сервисом.

Сервис в Kubernetes — абстракция, определяющая логический набор подов и политику доступа к ним (иногда такой набор подов еще называют микросервисом). Как правило, этот набор подов определяется на основе меток (присваиваются в момент создания подов) и селекторов.

### Endpoints
Определяют список конечных точек сети, на которые обычно ссылается служба, чтобы определить, на какие модули может быть отправлен трафик.

Поле appProtocolпредоставляет способ указать протокол приложения для каждого порта службы. Это используется как подсказка для реализаций, чтобы предложить более богатое поведение для протоколов, которые они понимают. Значение этого поля отражается соответствующими объектами Endpoints и EndpointSlice.

Проще говоря, Endpoint в Kubernetes — это "адресная книга" для сервиса, которая содержит IP-адреса и порты всех подов, к которым этот сервис должен направлять трафик.
### EndpointSlices

EndpointSlices — это улучшенная и более масштабируемая версия Endpoint в Kubernetes. Они используются для управления адресами подов (IP и порты), на которые может направлять трафик Service.


Когда у вас есть большой кластер с сотнями или тысячами подов, объект Endpoints может стать слишком большим, что приведёт к следующим проблемам:

* Масштабируемость:

    Один объект Endpoints может содержать все поды, управляемые сервисом. При большом количестве подов это создаёт нагрузку на API-сервер Kubernetes.
* Обновления:

    При изменении одного пода весь объект Endpoints приходится обновлять, что может вызвать высокую нагрузку на кластер.
    EndpointSlices решают эти проблемы, разбивая информацию о подах на небольшие группы.

### Cluster IP

Делает сервис доступным только внутри кластера. Это тип сервиса по умолчанию и используется, когда сервису не нужен доступ из внешней сети.
### NodePort

Обеспечивает доступ к сервису на каждом узле кластера через статический порт. Этот тип используется для того, чтобы сделать сервис доступным извне через IP любого узла кластера и заранее определенный порт.
### Load Balancer

Обеспечивает доступ к сервису с использованием внешнего балансировщика нагрузки. Kubernetes автоматически настроит внешний балансировщик, если используется облачная платформа, которая поддерживает эту опцию.
### External Name

Преобразует сервис Kubernetes в DNS-запись, ссылающуюся на внешний FQDN (полное доменное имя). Это полезно, если необходимо направлять трафик к внешним ресурсам, но при этом использовать Kubernetes-сервис для удобства.

### Headless Services

Headless-сервисы — это особый тип сервиса, который не обеспечивает балансировку нагрузки или IP-адрес кластера. Они являются «headless», потому что Kubernetes автоматически не проксирует через них трафик. Это позволяет вам использовать DNS-запросы для обнаружения индивидуальных IP-адресов любых Pod, выбранных сервисом.

Headless-сервис полезен, когда вы хотите взаимодействовать с другими системами обнаружения сервисов без вмешательства kube-proxy . Вы можете создать его, специально установив поле сервиса на значение.spec.clusterIPNone

### Network Policies

Если вы хотите контролировать поток трафика на уровне IP-адреса или порта для протоколов TCP, UDP и SCTP, то вы можете рассмотреть возможность использования Kubernetes NetworkPolicies для определенных приложений в вашем кластере. NetworkPolicies — это ориентированная на приложения конструкция, которая позволяет вам указать, как стручокразрешено взаимодействовать с различными сетевыми «сущностями» (мы используем здесь слово «сущность», чтобы избежать перегрузки более общих терминов, таких как «конечные точки» и «службы», которые имеют специфические коннотации Kubernetes) по сети. NetworkPolicies применяются к соединению с pod на одном или обоих концах и не имеют отношения к другим соединениям.

Сущности, с которыми может взаимодействовать Pod, идентифицируются с помощью комбинации следующих трех идентификаторов:

Другие разрешенные модули (исключение: модуль не может блокировать доступ к себе)
Разрешенные пространства имен
Блокировки IP (исключение: трафик к узлу, на котором запущен модуль, и от него всегда разрешен, независимо от IP-адреса модуля или узла)
При определении сетевой политики на основе пода или пространства имен вы используете селектордля указания того, какой трафик разрешен к и от Pod(ов), соответствующих селектору.

Между тем, при создании сетевых политик на основе IP-адресов мы определяем политики на основе блоков IP-адресов (диапазонов CIDR).


## Kubernetes Storage Objects
### Persistent Volume
PersistentVolume (PV) — это часть хранилища в кластере, которая была предоставлена ​​администратором или динамически предоставлена ​​с помощью Storage Classes . Это ресурс в кластере, как и узел — ресурс кластера. PV — это плагины томов, такие как Volumes, но имеют жизненный цикл, независимый от любого отдельного Pod, который использует PV. Этот объект API фиксирует детали реализации хранилища, будь то NFS, iSCSI или система хранения, специфичная для облачного провайдера.

### Persistent Volume Claim
Это объект, который служит запросом на использование постоянного хранилища (Persistent Volume, PV). PVC позволяет подам получать доступ к определённым ресурсам хранилища в соответствии с требованиями, такими как размер или режим доступа.

### Storage Class
StorageClass в Kubernetes — это абстракция, используемая для определения «классов» хранилища, предлагаемых кластером. Она позволяет администраторам кластера описывать различные типы хранилища, которые они могут предоставить, а также свойства этого хранилища, такие как производительность и доступность.

#### Ключевые компоненты StorageClass:
- Параметры

Каждый StorageClass может иметь различные параметры, определяющие конкретные настройки поставщика хранилища, такие как тип диска, IOPS (операции ввода-вывода в секунду) и факторы репликации.

- Поставщик

Поставщик — это бэкэнд хранилища, с которым взаимодействует Kubernetes для создания томов хранилища. Распространенные поставщики включают kubernetes.io/aws-ebs, kubernetes.io/gce-pd, и kubernetes.io/nfs.

- ReclaimPolicy

Политика reclaim определяет, что происходит с постоянным томом (PV), когда удаляется его соответствующее требование постоянного тома (PVC). Распространенные политики: Retain, Recycle, и Delete.

- Режим привязки

Режимы привязки определяют, когда должно происходить связывание тома и динамическое предоставление ресурсов. ImmediateПривязка происходит сразу после создания PVC, а WaitForFirstConsumerпривязка задерживается до тех пор, пока не будет запланирован Pod, использующий PVC.

- РазрешитьРасширениеОбъема

Это логическое поле позволяет пользователям изменять размер тома после его создания.

- MountOptions

Эти параметры определяют конкретные параметры монтирования для класса хранилища.
### Storage Class Provisioner
Поставщики хранилищ — это инструменты, которые предоставляют ресурсы хранения для контейнеров и приложений, работающих в кластере Kubernetes. Например, предположим, что приложению требуется том хранилища для хранения его данных. В этом случае поставщик может автоматически выделять пространство для хранения из облачного поставщика хранилища, системы сетевого хранилища (NAS) или локального диска на хост-машине. AWS EBS, Azure Files и GCE PD — все они входят в число самых популярных поставщиков хранилищ Kubernetes.
### Volume Snapshot
### VolumeSnapshotClass
Описывает параметры создания снимков, такие как драйвер CSI. Вы также можете указать там дополнительные настройки, например, должны ли снимки быть инкрементными и где они должны храниться.